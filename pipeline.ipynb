{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f835ae5a",
            "metadata": {},
            "source": [
                "# RAG Vector Index (and Sample Pipeline) Generation\n",
                "\n",
                "This notebook shows you how to and helps you create a RAG Vector Index from your data (Git repo)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "855c3bba",
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install azure-ai-ml\n",
                "%pip install -U 'azureml-rag[faiss]>=0.1.11'\n",
                "%pip install azureml-core\n",
                "%pip install azure-identity\n",
                "%pip install azureml-rag\n",
                "%pip install azureml.fsspec\n",
                "%pip install pandas\n",
                "%pip install openai~=0.27.8 # versioning for to allow dataplane deployment inferring\n",
                "%pip install python-dotenv\n",
                "%pip install --upgrade azure-ai-ml\n",
                "%pip install --upgrade azureml-core"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "038912d8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# If `import win32file` fails with a DLL error then run the following and restart kernel:\n",
                "# %pip uninstall -y pywin32\n",
                "# %conda install -y --force-reinstall pywin32"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5847419e",
            "metadata": {},
            "source": [
                "### .env File Setup\n",
                "\n",
                "Make sure to create a .env file in the same directory as this Jupyter notebook.\n",
                "The .env file needs to contain the following:\n",
                "\n",
                "```text\n",
                "AOAI_API_KEY=<AOAI_API_KEY>\n",
                "AOAI_ENDPOINT=<AOAI_TARGET_ENDPOINT>\n",
                "AOAI_API_VERSION=<AOAI_API_VERSION>\n",
                "GIT_REPO_URL=<GIT_REPO_URL>\n",
                "AOAI_CONNECTION_NAME=<AOAI_CONNECTION_NAME>\n",
                "AOAI_COMPLETION_MODEL_NAME=<AOAI_COMPLETION_MODEL_NAME>\n",
                "AOAI_COMPLETION_DEPLOYMENT_NAME=<AOAI_COMPLETION_DEPLOYMENT_NAME>\n",
                "AOAI_EMBEDDING_MODEL_NAME=<AOAI_EMBEDDING_MODEL_NAME>\n",
                "AOAI_EMBEDDING_DEPLOYMENT_NAME=<AOAI_EMBEDDING_DEPLOYMENT_NAME>\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0d764773",
            "metadata": {},
            "outputs": [],
            "source": [
                "from os import environ as env\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "print(\"Loading environment variables from .env file\")\n",
                "load_dotenv(\".env\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "91d587b0",
            "metadata": {},
            "source": [
                "### User Input Parameters\n",
                "\n",
                "Make sure to change the variables in the next section to fit your experiment needs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f47ef53c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# User Input\n",
                "git_url = '<GIT_REPO_URL>'\n",
                "data_source_url = '<GIT_REPO_SOURCE_URL>'\n",
                "chunk_size = \"1024\"\n",
                "chunk_overlap = \"0\"\n",
                "chunk_prepend_summary = False\n",
                "temperature = \"0.5\"\n",
                "max_tokens = \"2000\"\n",
                "serverless_instance_count = 1\n",
                "serverless_instance_type = \"Standard_D4s_v3\"\n",
                "embeddings_dataset_name = \"<VECTOR_INDEX_NAME>\"\n",
                "\n",
                "experiment_name = 'qa_faiss_index_generation'"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "1a99955c",
            "metadata": {},
            "source": [
                "## Get client for AzureML Workspace\n",
                "\n",
                "The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "63178816",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Defaults\n",
                "registry_name = \"azureml\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1cf46b08",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile workspace.json\n",
                "{\n",
                "    \"subscription_id\": \"<YOUR-SUBSCRIPTION-ID>\",\n",
                "    \"resource_group\": \"<YOUR-RESOURCE-GROUP-NAME>\",\n",
                "    \"workspace_name\": \"<YOUR-WORKSPACE-NAME>\"\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b1af37c8",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
                "from azure.ai.ml import MLClient\n",
                "from azureml.core import Workspace\n",
                "\n",
                "# try:\n",
                "#     credential = DefaultAzureCredential()\n",
                "#     # Check if given credential can get token successfully.\n",
                "#     credential.get_token(\"https://management.azure.com/.default\")\n",
                "# except Exception as ex:\n",
                "#     # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential does not work\n",
                "credential = InteractiveBrowserCredential()\n",
                "\n",
                "try:\n",
                "    ml_client = MLClient.from_config(credential=credential, path='workspace.json')\n",
                "except Exception as ex:    \n",
                "    raise Exception(\n",
                "        \"Failed to create MLClient from config file. Please modify and then run the above cell with your AzureML Workspace (associated with the AOAI connection) details.\"\n",
                "    ) from ex\n",
                "ws = Workspace(subscription_id=ml_client.subscription_id, resource_group=ml_client.resource_group_name, workspace_name=ml_client.workspace_name)\n",
                "print(ml_client)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "30906d39",
            "metadata": {},
            "source": [
                "## Azure OpenAI\n",
                "\n",
                "We recommend using gpt-35-turbo model or newer to get good quality output. [Follow these instructions](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) to setup an Azure OpenAI Instance and deploy the model. Once you have the model deployed in AOAI you can specify your Model name and Deployment name below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ab3f1c33",
            "metadata": {},
            "outputs": [],
            "source": [
                "aoai_completion_model_name = env['AOAI_COMPLETION_MODEL_NAME']\n",
                "aoai_completion_deployment_name = env['AOAI_COMPLETION_DEPLOYMENT_NAME']\n",
                "aoai_embedding_model_name = env['AOAI_EMBEDDING_MODEL_NAME']\n",
                "aoai_embedding_deployment_name = env['AOAI_EMBEDDING_DEPLOYMENT_NAME']\n",
                "aoai_connection = env['AOAI_CONNECTION_NAME']"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89e86fd3",
            "metadata": {},
            "source": [
                "Everything below this point does not require user input! Time to watch the magic happen :\\) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "129ac0b7",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azureml.rag.utils.connections import get_connection_by_name_v2, create_connection_v2\n",
                "\n",
                "try:\n",
                "    aoai_connection = get_connection_by_name_v2(ws, aoai_connection)\n",
                "    aoai_connection_id = aoai_connection['id']\n",
                "except Exception as ex:\n",
                "    print(f\"Could not get connection '{aoai_connection}', creating a new one\")\n",
                "\n",
                "    target = env['AOAI_ENDPOINT'] # example: 'https://<endpoint>.openai.azure.com/'\n",
                "    key = env['AOAI_API_KEY']\n",
                "    apiVersion = env['AOAI_API_VERSION'] # 2023-03-15-preview\n",
                "    \n",
                "    if(key is None):\n",
                "        raise RuntimeError(f\"Please provide a valid key for the Azure OpenAI service\")\n",
                "    if(target is None):  \n",
                "        raise RuntimeError(f\"Please provide a valid target for the Azure OpenAI service\")\n",
                "    if(apiVersion is None):\n",
                "        raise RuntimeError(f\"Please provide a valid api-version for the Azure OpenAI service\")\n",
                "    aoai_connection_id = create_connection_v2(\n",
                "        workspace=ws,\n",
                "        name=aoai_connection,\n",
                "        category='AzureOpenAI',\n",
                "        target=target,\n",
                "        auth_type='ApiKey',\n",
                "        credentials={\n",
                "            'key': key\n",
                "        },\n",
                "        metadata={\n",
                "            'apiType': 'azure',\n",
                "            'apiVersion': apiVersion\n",
                "        }\n",
                "    )['id']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c1e5cc13",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment to upgrade azureml-rag if infer_deployment is unrecognized in the package\n",
                "# %pip install azureml-rag --upgrade\n",
                "\n",
                "from azureml.rag.utils.deployment import infer_deployment\n",
                "\n",
                "aoai_completion_deployment_name = infer_deployment(aoai_connection, aoai_completion_model_name)\n",
                "print(f\"Deployment name in AOAI workspace for model '{aoai_completion_model_name}' is '{aoai_completion_deployment_name}'\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "56878876",
            "metadata": {},
            "source": [
                "### Setup Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e2a3752a",
            "metadata": {},
            "outputs": [],
            "source": [
                "ml_registry = MLClient(credential=credential, registry_name = registry_name)\n",
                "git_to_faiss_component = ml_registry.components.get('llm_ingest_git_to_faiss_basic', label='latest')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "53285c16",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azure.ai.ml import Output\n",
                "from azure.ai.ml.dsl import pipeline\n",
                "\n",
                "# def use_automatic_compute(component, instance_count=1, instance_type='Standard_D4s_v3'):\n",
                "#     component.set_resources(instance_count=instance_count, instance_type=instance_type, properties={'compute_specification': {'automatic': True}})\n",
                "#     return component\n",
                "\n",
                "# def use_aoai_connection(component, aoai_connection_id, custom_env:str=None):\n",
                "#     if custom_env is not None:\n",
                "#         component.environment_variables[custom_env] = aoai_connection_id\n",
                "#     if aoai_connection_id is not None:\n",
                "#         component.environment_variables['AZUREML_WORKSPACE_CONNECTION_ID_AOAI'] = aoai_connection_id\n",
                "\n",
                "# @pipeline(compute=dedicated_cpu_compute)\n",
                "@pipeline(default_compute='serverless')\n",
                "def qa_faiss_index_generation(\n",
                "    git_url,\n",
                "    data_source_url,\n",
                "    llm_completion_config,\n",
                "    embeddings_model,\n",
                "    aoai_connection_id=None,\n",
                "    chunk_size=1024,\n",
                "    chunk_overlap=0,\n",
                "    chunk_prepend_summary=False,\n",
                "    serverless_instance_count=1,\n",
                "    serverless_instance_type=\"Standard_D4s_v3\",\n",
                "    embeddings_dataset_name=\"git-repository_VectorIndex\",\n",
                "):\n",
                "\n",
                "    # Ingest Git to Faiss Vector Index\n",
                "    git_to_faiss = git_to_faiss_component(\n",
                "        git_repository = git_url,\n",
                "        data_source_url = data_source_url,\n",
                "        llm_config = llm_completion_config,\n",
                "        llm_connection = aoai_connection_id,\n",
                "        embeddings_model = embeddings_model,\n",
                "        embedding_connection = aoai_connection_id,\n",
                "        chunk_size = chunk_size,\n",
                "        chunk_overlap = chunk_overlap,\n",
                "        chunk_prepend_summary = chunk_prepend_summary,\n",
                "        serverless_instance_count = serverless_instance_count,\n",
                "        serverless_instance_type = serverless_instance_type,\n",
                "        embeddings_dataset_name = embeddings_dataset_name,\n",
                "    )\n",
                "\n",
                "\n",
                "    return {\n",
                "        'qa_faiss_index': git_to_faiss.outputs.faiss_index,\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2cd4b8bf",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Defaults\n",
                "embeddings_model = f'azure_open_ai://deployment/{aoai_embedding_deployment_name}/model/{aoai_embedding_model_name}'\n",
                "llm_completion_config = f'{{\"type\":\"azure_open_ai\",\"model_name\":\"{aoai_completion_model_name}\",\"deployment_name\":\"{aoai_completion_deployment_name}\",\"temperature\":\"{temperature}\",\"max_tokens\":\"{max_tokens}\"}}'\n",
                "print(embeddings_model)\n",
                "print(llm_completion_config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3f5d18c8",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azure.ai.ml import Input\n",
                "from azure.ai.ml.entities import UserIdentityConfiguration\n",
                "\n",
                "# data_source_glob=data_source_glob,\n",
                "# asset_name=asset_name,\n",
                "# document_path_replacement_regex=document_path_replacement_regex,\n",
                "pipeline_job = qa_faiss_index_generation(\n",
                "    git_url = git_url,\n",
                "    data_source_url = data_source_url,\n",
                "    llm_completion_config = llm_completion_config,\n",
                "    embeddings_model = embeddings_model,\n",
                "    aoai_connection_id=aoai_connection_id,\n",
                "    chunk_size = chunk_size,\n",
                "    chunk_overlap = chunk_overlap,\n",
                "    chunk_prepend_summary = chunk_prepend_summary,\n",
                "    serverless_instance_count=serverless_instance_count,\n",
                "    serverless_instance_type=serverless_instance_type,\n",
                "    embeddings_dataset_name=embeddings_dataset_name,\n",
                ")\n",
                "\n",
                "pipeline_job.identity = UserIdentityConfiguration()\n",
                "pipeline_job.settings.continue_on_step_failure = False"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "67f89a25",
            "metadata": {},
            "source": [
                "### Submit Pipeline\n",
                "Click on the generated link below access the job details on studio. Make sure all necessary flights are added on the URL to access these preview features.\n",
                "\n",
                "**In case of any errors see [TROUBLESHOOT.md](../../TROUBLESHOOT.md).**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "52d9b2be",
            "metadata": {},
            "outputs": [],
            "source": [
                "running_pipeline_job = ml_client.jobs.create_or_update(\n",
                "    pipeline_job, experiment_name=experiment_name\n",
                ")\n",
                "running_pipeline_job"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "e598a8a4",
            "metadata": {},
            "source": [
                "### Review token usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f97a1a98",
            "metadata": {},
            "outputs": [],
            "source": [
                "# running_pipeline_job = ml_client.jobs.get(\"<pipeline run id>\")\n",
                "child_runs = ml_client.jobs.list(parent_job_name=running_pipeline_job.name)\n",
                "child_runs = list(child_runs)\n",
                "data_generation_run = child_runs[-1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "369793ed",
            "metadata": {},
            "outputs": [],
            "source": [
                "from azureml.core import Run\n",
                "\n",
                "run = Run.get(ws, data_generation_run.name)\n",
                "metrics = run.get_metrics()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dbed9c85",
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(f\"Tokens used: {metrics['total_tokens']}\")\n",
                "# print(f\"Model used: {metrics['llm_model_name']}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "69b9772c",
            "metadata": {},
            "source": [
                "Given the token usage and the model you can compute cost using the pricing here: https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}